# Performance

## Setup

```elixir
Mix.install([
  {:vega_lite, "~> 0.1.3"},
  {:kino, github: "livebook-dev/kino"},
  {:benchee, "~> 1.0"}
])

alias VegaLite, as: Vl
```

## Performance Concerns

Computers are broken into a variety of parts. As programmers, we are primarily concerned about
 the **processor**, and the **memory**.

The processor determines the computer's ability to make calculations. It's speed is measured
in GHz (Gigahertz).

Memory or **RAM** (random access memory) is measured in GB (Gigabytes) and is the amount of data
we can store during a calculation.

In software terms, this translates to the **speed** and **memory consumption** of our program. Generally
as you build software, those are your main performance concerns.

While computers are incredibly fast, they do have limits. Certain calculations take time to complete.
So, we need to be mindful of how to optimize our programs to operate efficiently.

For example, this statement may take some time.

```elixir
Enum.map(1..10_000_000, fn each -> each + 2 end)
```

## Linear Growth

The amount of time it takes to complete the above calculation grows linearly as we increase the number of
elements in the range.

For each additional item added to the collection, the computer needs to
perform approximately the same number of additional calculations.

Plotted onto a graph you would expect that as we increase the number of elements, expected time grows in a constant line upward.

```elixir
# TODO - Hide

size = 600

widget =
  Vl.new(width: size, height: size)
  |> Vl.mark(:line)
  |> Vl.encode_field(:x, "number of elements", type: :quantitative)
  |> Vl.encode_field(:y, "time", type: :quantitative)
  |> Vl.encode_field(:color, "type", title: "Linear Growth", type: :nominal)
  |> Kino.VegaLite.new()
  |> Kino.render()

base = 100
init = 1
max = 5000

linear =
  Enum.map(init..max, fn each ->
    # {time, _value} = :timer.tc(fn -> Enum.map(1..each, fn each -> each + 2 end) end)
    %{"number of elements": each, time: each, type: "O(n)"}
  end)

Kino.VegaLite.push_many(widget, linear)
```

## Polonomial Growth

Some calculation instead follow polonomial growth, where the number of calculations necessary 
increases with each additonal element. Typically polonomial growth doubles for each element,
but it can triple, quaduple, etc.

### Your Turn

For example, this function creates a larger list with each enumeration.

Try changing `number` to `2`, `3`, and `4`. Notice how it creates more lists, with more
elements for each increase in number.

```elixir
number = 1

Enum.map(1..number, fn _ ->
  Enum.to_list(1..number)
end)
```

* With 1 element it creates 1 element
* With 2 elements it creates 4 elements
* With 3 elements it creates 9 elements
* With 4 elements it creates 12 elements

In other words, it creates $$n^2$$ elements.

```elixir
# TODO - Hide

data =
  Enum.map(1..10, fn each ->
    %{
      "# of elements": each,
      result: each ** 2,
      notation: "#{each}**2",
      equation: "#{each} * #{each}"
    }
  end)

Kino.DataTable.new(data)
```

Plotted onto a graph, you would expect an upward curve for polonomial growth.
While the previous example was $n^2$, polonomial growth can also be $n^3$, $n^4$, and so on.

```elixir
# TODO - Hide
size = 600

widget =
  Vl.new(width: size, height: size)
  |> Vl.mark(:line)
  |> Vl.encode_field(:x, "number of elements", type: :quantitative)
  |> Vl.encode_field(:y, "time", type: :quantitative)
  |> Vl.transform(groupby: ["color"], extent: [2500, 6500])
  |> Vl.encode_field(:color, "type", title: "Polonomial Growth", type: :nominal)
  |> Kino.VegaLite.new()
  |> Kino.render()

init = 1
max = 5

n2 =
  Enum.map(init..max, fn number_of_elements ->
    %{"number of elements": number_of_elements, time: number_of_elements ** 2, type: "n^2"}
  end)

n3 =
  Enum.map(init..max, fn number_of_elements ->
    %{"number of elements": number_of_elements, time: number_of_elements ** 3, type: "n^3"}
  end)

n4 =
  Enum.map(init..max, fn number_of_elements ->
    %{"number of elements": number_of_elements, time: number_of_elements ** 4, type: "n^4"}
  end)

Kino.VegaLite.push_many(widget, n2)
Kino.VegaLite.push_many(widget, n3)
Kino.VegaLite.push_many(widget, n4)
```

## Exponential Growth

Certain functions grow exponentially, often enumerating through every possible permutation of
the input. As you can imagine this is computationally expensive.

For example, if you needed to calculate every permutation of a number, that would require
an exponential function.

<!-- livebook:{"break_markdown":true} -->

```mermaid
flowchart
  a[123]
  a --> b[1]
  a --> c[2]
  a --> d[3]
  b --> b1[2] --> 123
  b --> b2[3] --> 132
  c --> c1[1] --> 213
  c --> c2[3] --> 231
  d --> d1[1] --> 312
  d --> d2[2] --> 321
```

```elixir
# TODO - Hide
size = 600

widget =
  Vl.new(width: size, height: size)
  |> Vl.mark(:line)
  |> Vl.encode_field(:x, "x", type: :quantitative)
  |> Vl.encode_field(:y, "y", type: :quantitative)
  |> Vl.transform(groupby: ["color"], extent: [2500, 6500])
  |> Vl.encode_field(:color, "type", title: "Exponential Growth", type: :nominal)
  |> Kino.VegaLite.new()
  |> Kino.render()

init = 1
max = 5

linear =
  Enum.map(init..max, fn number_of_elements ->
    %{x: number_of_elements, y: number_of_elements ** number_of_elements, type: "n^n"}
  end)

Kino.VegaLite.push_many(widget, linear)
```

```elixir
# TODO - Hide

data =
  Enum.map(1..10, fn each ->
    %{"# of elements": each, result: each ** each, equation: "#{each} ** #{each}"}
  end)

Kino.DataTable.new(data)
```

## Big O Notation

As programmers, we are generally more concerned with how performance cost grows in our
program.

We use **Big $$O$$ Notation** to communicate about how performance changes based on the size
of the data.

* **$$O(1)$$**: Constant Time
* **$$O(log (n))$$**: Logarithmic Time
* **$$O(n)$$**: Linear Time
* **$$O(n^2)$$**: Quadratic Time (Polonomial Time)
* **$$O(n^n)$$**: Exponential Time
* **$$O(n!)$$**: Factorial Time

```elixir
# TODO - Hide
size = 600

widget =
  Vl.new(width: size, height: size)
  |> Vl.mark(:line)
  |> Vl.encode_field(:x, "x", type: :quantitative)
  |> Vl.encode_field(:y, "y", type: :quantitative)
  |> Vl.transform(groupby: ["color"], extent: [2500, 6500])
  |> Vl.encode_field(:color, "type", title: "Big O Notation", type: :nominal)
  |> Kino.VegaLite.new()
  |> Kino.render()

max_x = 5
initial_x = 2

linear = Enum.map(initial_x..max_x, &%{x: &1, y: &1, type: "O(n)"})
constant = Enum.map(initial_x..max_x, &%{x: &1, y: 1, type: "O(1)"})
polonomial = Enum.map(initial_x..max_x, &%{x: &1, y: &1 ** 2, type: "O(n^2)"})
logarithmic = Enum.map(initial_x..max_x, &%{x: &1, y: :math.log2(&1), type: "O(log n)"})
exponential = Enum.map(initial_x..(max_x - 2), &%{x: &1, y: &1 ** &1, type: "O(n^n)"})

Kino.VegaLite.push_many(widget, exponential)
Kino.VegaLite.push_many(widget, polonomial)
Kino.VegaLite.push_many(widget, logarithmic)
Kino.VegaLite.push_many(widget, constant)
Kino.VegaLite.push_many(widget, linear)
```

Different big $O$ complexities grow far faster than others.
See the graph below for a general ranking.

<!-- livebook:{"break_markdown":true} -->

![](images/big_o_notation_graph.png)

<!-- livebook:{"break_markdown":true} -->

When performance is a concern, you should try to be aware of the performance costs and memory costs of both the
code that your write, and the built-in functionality you use.

This will inspire both how you write code, and which data structures you choose for particular situations.

<!-- livebook:{"break_markdown":true} -->

### Your Turn

Evaluate the Elixir cell below to view the exercise.

````elixir
# TODO - Hide
Kino.Input.text("What is the Big O Notation for the following?") |> Kino.render()

Kino.Markdown.new("
```elixir
1 + 1
```
") |> Kino.render()

# TODO - Hide
Kino.Input.text(
  "As elements are added to the `map`, what is the Big O Notation for the following?"
)
|> Kino.render()

Kino.Markdown.new("
```elixir
map = %{key: \"value\"}
map.key
```
") |> Kino.render()

Kino.Input.text(
  "As elements are added to `list`, what is the Big O Notation for the following code?"
)
|> Kino.render()

Kino.Markdown.new("
```elixir
list = [1,2,3]
Enum.map([1, 2, 3], fn each -> each  + 2 end)
```
") |> Kino.render()

Kino.Input.text(
  "As elements are added to `list`, what is the Big O Notation for the following code?"
)
|> Kino.render()

Kino.Markdown.new("
```elixir
list = [1,2,3]
Enum.map([1, 2, 3], fn element1 -> 
  Enum.map(list, fn element2 -> {element1, element2} )
end)
```
")
````

## Measuring Performance

Big $O$ Notation allows us to reason about how processing speed and memory consuption will grow
given larger data sets for a calculation.

This is useful for theorizing about performance. In practice, it's best to test your assumptions.
By testing performance, we can avoid pre-optimizing code before it's necessary. We can also know which
pieces of code cost the most.

There's a wide variety of tools for measuring and monitoring performance. We'll focus on
benchmarking time and memory consumption for now.

### :timer.tc/1

Out of the box, Erlang provides a `:timer` library which contains a `tc/1` function to measure the time it takes to run a function.
It returns a `{time, result}` tuple.

```mermaid
flowchart LR
Function --> timer[:timer.tc/1] --> return["{timer, result}"]
```

```elixir
:timer.tc(fn -> 10000 ** 10000 - 10000 ** 10000 + 1 end)
```

The `time` returned is measured in nanoseconds.

`1000` nanoseconds equals `1` milisecond.
`1000` miliseconds equals `1` seconds.

So you can get the number of miliseconds the function takes to run by dividing the result by `1000`

```elixir
{time, _result} = :timer.tc(fn -> 10000 ** 10000 - 10000 ** 10000 + 1 end)
miliseconds = time / 1000
```

And the number of seconds by dividing once again by `1000`.

```elixir
seconds = miliseconds / 1000
```

### Benchee

[Benchee](https://github.com/bencheeorg/benchee)
is a popular library for measuring performance and memory consumption.

External libraries need to be installed to use them.

We use [Mix](https://hexdocs.pm/mix/1.13/Mix.html) to install Benchee.

Mix is a build tool that provides tasks for creating, compiling, and testing Elixir projects, managing its dependencies, and more.

<!-- livebook:{"break_markdown":true} -->

```mermaid
flowchart LR
Benchee
D[Dependencies]
I[install/2]
Mix
Mix --> I
I --> D
D --> Benchee
```

<!-- livebook:{"break_markdown":true} -->

You'll learn more about Mix in future lessons. For now, it's enough to be aware that you won't be able 
to use the Benchee library unless it's installed.

We've installed Benchee for you for this lesson, but don't be suprised if you try to use Benchee in
other lessons and it isn't installed.

We can use the `Benchee.run/2` function to measure the performance and memory consumption of some code.

```elixir
Benchee.run(%{
  "example test" => fn -> 10000 ** 10000 end
})
```

Above, the most imporant part of the output should look like the following, but with different numbers.

```
Name                   ips        average  deviation         median         99th %
example test        154.65        6.47 ms    ±26.50%        6.13 ms       13.17 ms

Memory usage statistics:

Name            Memory usage
example test           600 B
```

<!-- livebook:{"break_markdown":true} -->

The Benchee documentation explains how to read the output:

> * average - average execution time/memory usage (the lower the better)
> * ips - iterations per second, aka how often can the given function be executed within one second (the higher the better - good for graphing), only for run times
> * deviation - standard deviation (how much do the results vary), given as a percentage of the average (raw absolute values also available)
> * median - when all measured values are sorted, this is the middle value. More stable than the average and somewhat more likely to be a typical value you see, for the most typical value see mode. (the lower the better)
> * 99th % - 99th percentile, 99% of all measured values are less than this - worst case performance-ish

<!-- livebook:{"break_markdown":true} -->

### Using Benchee For Comparison

let's use Benchee to compare tuples and lists. Tuples are intended to be used as fixed-sized
containers that are fast for accessing. Lists are collections intended for dynamic sized containers that get modified.

Therefore, lists should be slow to access, and tuples should be fast to access. That's in theory, let's
verify our assumption and prove it to be true.

```elixir
large_list = Enum.to_list(0..10000)
large_tuple = List.to_tuple(large_list)

Benchee.run(%{
  "list" => fn -> Enum.at(large_list, 10000) end,
  "tuple" => fn -> elem(large_tuple, 10000) end
})
```

Upon running the above, you should see an output similar to the following. You'll notice that
accessing a list was far slower!

```
Name            ips        average  deviation         median         99th %
tuple        1.09 M        0.92 μs  ±2806.65%        0.80 μs           2 μs
list       0.0324 M       30.89 μs    ±93.31%       28.90 μs       67.80 μs

Comparison: 
tuple        1.09 M
list       0.0324 M - 33.58x slower +29.97 μs
```

<!-- livebook:{"break_markdown":true} -->

### Your Turn

Use Benchee to compare accessing the **first** element instead of the last element as we already did above.
You should notice the list is faster this time, or at least about the same speed. You'll learn why in a future lesson.

```elixir
large_list = Enum.to_list(0..10000)
large_tuple = List.to_tuple(large_list)

Benchee.run(%{
  "list" => fn -> Enum.at(large_list, 0) end,
  "tuple" => fn -> elem(large_tuple, 0) end
})
```
